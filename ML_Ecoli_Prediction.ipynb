{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3644deba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d1e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Read Data ########################################################\"\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "##############################################\n",
    "VERBOSE_VALUE = 0 # Display GridSearch execution logs\n",
    "TEST_SIZE_VALUE = 0.1 # Dataset rate to ue in the test step\n",
    "CROSS_VALID = 5 # Number of K for cross validation\n",
    "###############################################\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"/home/manel/Bureau/BD/donnee+pluvio/smv-complet/donnee_brute_sans_na/smv.csv\")\n",
    "### Remove All empty values\n",
    "data = data.fillna(0) \n",
    "\n",
    "X = data.drop([\"Ecoli\",\"EI\"],axis=1)\n",
    "y = data.iloc[:,2]\n",
    "data=data.drop([\"EI\"],axis=1)\n",
    "\n",
    "print(X)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abfe471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "######################################## Data Information ########################################################\"\n",
    "print(\"  * * * * * * * I)  Dataframe information * * * * * * *  \")\n",
    "print(\" 1) Statistics  _  describe ()  \")\n",
    "print(data.describe())\n",
    "print(\"______________________________________\")\n",
    "print(\" 2) Informaton (Column, Non-Null, Count, Dtype)  _  info ()  \")\n",
    "print(data.info())\n",
    "\n",
    "print(\"TYPE === \",type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive analysis of the data\n",
    "#! pip install pandas_profiling\n",
    "from pandas_profiling import ProfileReport\n",
    "prof = ProfileReport(data, title='Analyse du jeu de la Marne', html={'style':{'full_width':True}})\n",
    "prof.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57273dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## Data Split  #########################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "# Split data on training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE_VALUE, random_state=0)\n",
    "# The split is done randomly by dividing into training and test data \n",
    "# The random state allows to have a seed for reproducibility. \n",
    "# Changing the value modifies the split applied to the data in order to have different training and test sets. \n",
    "\n",
    "\n",
    "# Remove the date column from the data training\n",
    "X_train = X_train.drop([\"date\"],axis=1)\n",
    "\n",
    "# Create the data test to export\n",
    "DataToExport = X_test\n",
    "df_Ytest = pd.DataFrame(data=y_test.values, columns=['list'])\n",
    "\n",
    "pieces = {'x': DataToExport, 'y': df_Ytest}\n",
    "\n",
    "DataToExport = pd.concat(pieces)\n",
    "\n",
    "# Print the data to export \n",
    "print(DataToExport)\n",
    "\n",
    "print(\"  * * * * * * * -- Export -- * * * * * * *  \")\n",
    "X_test.to_csv ('data_Test.csv', index = False, header=True, sep=\";\")\n",
    "DataToExport = pd.read_csv(\"data_Test.csv\", sep=\";\")\n",
    "print(type(DataToExport))\n",
    "df_Ytest = pd.DataFrame(data=y_test.values)\n",
    "DataToExport[\"Ecolireal\"] = df_Ytest\n",
    "print(\"  * * * * * * * -- DATA TEST building -- OK -- * * * * * * *  \")\n",
    "X_test = X_test.drop([\"date\"],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afea18e",
   "metadata": {},
   "source": [
    "### Data standardization\n",
    "\n",
    "Standardization allows scaling before training. It will be performed on the training data so that the models do not have access to the values in the test dataset.\n",
    "Standardization by the mean: Subtract the mean and divide by the standard deviation for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean and standard deviation values\n",
    "X_train, X_test, y_train, y_test\n",
    "train_mean = X_train.mean()\n",
    "train_std = X_train.std()\n",
    "y_mean = y_train.mean()\n",
    "y_std = y_train.std()\n",
    "\n",
    "X_train = (X_train - train_mean) / train_std\n",
    "X_test = (X_test - train_mean) / train_std\n",
    "y_train = (y_train - y_mean) / y_std\n",
    "y_test = (y_test - y_mean) / y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c5a6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b25cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908a452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determination of the standard deviation after standardization. \n",
    "import numpy as np\n",
    "sd=np.std(y_test)\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1285b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### ---------------------- Imports ----------------------------------------------------------------------\n",
    "from sklearn.model_selection import GridSearchCV # Create the parameter grid based on the results of random search\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "##############################################################################################\"\n",
    "######################################## MODEL KNN Split  ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "\n",
    "## --- Local Params\n",
    "modelName = \"KNN\"\n",
    "MethodID = \"A\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "param_gridKNN = {'n_neighbors': np.arange(1, 30, 2),\n",
    "              'weights': ['uniform', 'distance']\n",
    "         }\n",
    "\n",
    "\n",
    "# Selection of the best model\n",
    "modelKNN =  KNeighborsRegressor()\n",
    "best_model_searchKNN = GridSearchCV(estimator = modelKNN, param_grid = param_gridKNN, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchKNN.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Show which is the best model\n",
    "best_grid = best_model_searchKNN.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Predict the values using best_model\n",
    "Y_pred_KNN = best_model_searchKNN.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Errors for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_KNN)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_KNN)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_KNN)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Export the model\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-SMV-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchKNN, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "#Destandardization of predicted values\n",
    "Y_pred_KNN = (Y_pred_KNN*y_std)+ y_mean\n",
    "DataToExport[\"KNN_Ecoli_pred\"] = Y_pred_KNN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bf486",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## MODEL RF  Split  ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"RF\"\n",
    "MethodID = \"B\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "param_gridRF = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': [2,3,4,5,6,7,8,9,10,11],\n",
    "    'n_estimators': [10, 50, 200]\n",
    "}\n",
    "\n",
    "\n",
    "# Selection of the best model\n",
    "modelRF =  RandomForestRegressor()\n",
    "best_model_searchRF = GridSearchCV(estimator = modelRF, param_grid = param_gridRF, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchRF.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Show which is the best model\n",
    "best_grid = best_model_searchRF.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Predict the values using best_model\n",
    "Y_pred_RF = best_model_searchRF.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Errors for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_RF)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_RF)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_RF)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Export the model\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-SMV-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchRF, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "#Destandardization of predicted values\n",
    "Y_pred_RF = (Y_pred_RF*y_std)+ y_mean\n",
    "DataToExport[\"RF_Ecoli_pred\"] = Y_pred_RF\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd75d10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## MODEL DT  Split  ####################################\"\n",
    "####################################### Arbre de decision ####################################\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"DT\"\n",
    "MethodID = \"C\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "param_gridDT = {\"max_depth\": [1, 2, 10, 100],\n",
    "              \"random_state\":[1, 2, 10, 100],\n",
    "              \"min_samples_leaf\":[1, 2, 10, 100]\n",
    "         }\n",
    "\n",
    "\n",
    "# Selection of the best model\n",
    "modelDT =  tree.DecisionTreeRegressor()\n",
    "best_model_searchDT = GridSearchCV(estimator = modelDT, param_grid = param_gridDT, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchDT.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Show which is the best model\n",
    "best_grid = best_model_searchDT.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Predict the values using best_model\n",
    "Y_pred_DT = best_model_searchDT.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Errors for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_DT)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_DT)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_DT)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Export the model\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-SMV-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchDT, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "#Destandardization of predicted values\n",
    "Y_pred_DT = (Y_pred_DT*y_std)+ y_mean\n",
    "DataToExport[\"DT_Ecoli_pred\"] = Y_pred_DT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d4ef5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "######################################## MODEL SVM  Split  ####################################\"\n",
    "################################ Machine a vecteurs de support  ###############################\"\n",
    "######################################### non lineaire ########################################\"\n",
    " \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"SVM\"\n",
    "MethodID = \"D\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "param_gridSVM = {'kernel' : ('sigmoid', 'rbf'),\n",
    "         'coef0' : [0.01,10,0.5],\n",
    "         'gamma' : ('auto','scale')\n",
    "         }\n",
    "\n",
    "\n",
    "# Selection of the best model\n",
    "modelSVM = SVR()\n",
    "best_model_searchSVM = GridSearchCV(estimator = modelSVM, param_grid = param_gridSVM, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchSVM.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Show which is the best model\n",
    "best_grid = best_model_searchSVM.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Predict the values using best_model\n",
    "Y_pred_SVM = best_model_searchSVM.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Errors for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_SVM)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_SVM)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_SVM)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Export the model\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-SMV-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchSVM, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "#Destandardization of predicted values \n",
    "Y_pred_SVM = (Y_pred_SVM*y_std)+ y_mean\n",
    "DataToExport[\"SVM_Ecoli_pred\"] = Y_pred_SVM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "#################################### MODEL AdaBoost  Split  ##################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"AdaBoost\"\n",
    "MethodID = \"E\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "#from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "param_gridADaBoost = {'base_estimator__min_samples_leaf':[1,2, 5],\n",
    "              \"learning_rate\": [0.2,0.5],\n",
    "              \"n_estimators\": [20, 50, 100]\n",
    "         }\n",
    "\n",
    "\n",
    "# Selection of the best model\n",
    "from sklearn import tree\n",
    "DTC = tree.DecisionTreeRegressor(random_state = 11, max_features = \"auto\",\n",
    "                                 max_depth = None)\n",
    "ModelAdaBoostDTC = AdaBoostRegressor(base_estimator = DTC)\n",
    "best_model_searchAdaBoost = GridSearchCV(estimator = ModelAdaBoostDTC, param_grid = param_gridADaBoost, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchAdaBoost.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Show which is the best model\n",
    "best_grid = best_model_searchAdaBoost.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Predict the values using best_model\n",
    "Y_pred_AdaBoost = best_model_searchAdaBoost.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Errors for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_AdaBoost)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_AdaBoost)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_AdaBoost)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Export the model\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-SMV-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchAdaBoost, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "#Destandardization of predicted values \n",
    "Y_pred_AdaBoost = (Y_pred_AdaBoost*y_std)+ y_mean\n",
    "DataToExport[\"AdaBoost_Ecoli_pred\"] = Y_pred_AdaBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0f50a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "############################## MODEL Bagging avec estimator RF ###############################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "## --- Local Params\n",
    "modelName = \"BaggingRF\"\n",
    "MethodID = \"H\"\n",
    "\n",
    "print( \" ################# ------------- ########################## \")\n",
    "print( \"Model \" ,modelName,\" is runing ........ !  \")\n",
    "\n",
    "\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "X, y = make_regression(n_samples=100, n_features=11,n_informative=2, n_targets=1, random_state=0, shuffle=False)\n",
    "\n",
    "param_gridBag = {\n",
    "    'bootstrap': [True],\n",
    "    'max_features': [0, 11],\n",
    "    'n_estimators': [10, 50, 200]\n",
    "}\n",
    "\n",
    "\n",
    "# Selection of the best model\n",
    "modelRF =  RandomForestRegressor()\n",
    "modelBaggingRF = BaggingRegressor(base_estimator=modelRF, n_estimators=10, random_state=0).fit(X, y) # base estimator par defaut DesicionTreeRegressor\n",
    "\n",
    "best_model_searchBag2 = GridSearchCV(estimator = modelBaggingRF, param_grid = param_gridBag, cv = CROSS_VALID,\n",
    "                           verbose = VERBOSE_VALUE)\n",
    "best_model_searchBag2.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "#  Show which is the best model\n",
    "best_grid = best_model_searchBag2.best_estimator_\n",
    "print(\"  ------------------------------------  \")\n",
    "print (MethodID+\"-1) BEST Configuration (\"+modelName+\") is  ==== \",best_grid )\n",
    "print(\"  ------------------------------------  \")\n",
    "\n",
    "\n",
    "# Predict the values using best_model\n",
    "Y_pred_Bag2 = best_model_searchBag2.predict(X_test)\n",
    "Y=y_test\n",
    "num_data = X.shape[0]\n",
    "\n",
    "\n",
    "# Errors for performance evaluation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "mse = mean_squared_error(Y,Y_pred_Bag2)\n",
    "rmse = math.sqrt(mse)\n",
    "rse = math.sqrt(mse/(num_data-2))\n",
    "mae=mean_absolute_error(Y,Y_pred_Bag2)\n",
    "\n",
    "print(MethodID+\"-2) Evaluation  \"+modelName+\" Results : \")\n",
    "print(\"--> RMSE ((\"+modelName+\"))=\",rmse)\n",
    "print(\"--> MAE ((\"+modelName+\"))=\",mae)\n",
    "r = scipy.stats.pearsonr(Y,Y_pred_Bag2)\n",
    "print(\"--> Pearson Correlation ((\"+modelName+\"))=\",r)\n",
    "\n",
    "\n",
    "# Export the model\n",
    "import pickle\n",
    "filename = 'bestModel'+modelName+'-SMV-nrml-Ecoli.pickle'\n",
    "pickle.dump(best_model_searchBag2, open(filename, 'wb'))\n",
    "print(\"  ------------------------------------  \")\n",
    "print( MethodID+\"-3) Model \" ,modelName,\" is generated and exported -- OK --  \")\n",
    "print( \" ################# ------------- ########################## \")\n",
    "\n",
    "#Destandardization of predicted values \n",
    "Y_pred_Bag2 = (Y_pred_Bag2*y_std)+ y_mean\n",
    "DataToExport[\"Bagging_Ecoli_pred\"] = Y_pred_Bag2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ff102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data to export \n",
    "DataToExport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343950bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################## Export the data  ####################################\"\n",
    "\n",
    "# Export the data with the prediction values for all models \n",
    "print( \" ======================================================= \")\n",
    "print( \" ======================================================= \")\n",
    "print(\"  * * * * * * * IV) Export CSV  * * * * * * *  \")\n",
    "DataToExport.to_csv ('/home/manel/Bureau/BD/donnee+pluvio/smv-complet/ML/data_prediValuesML_ecoli_smv.csv', index = False, header=True, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358a8de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################################\"\n",
    "################################### Analyse the RF model  ####################################\"\n",
    "##############################################################################################\"\n",
    "\n",
    "#! pip install treeinterpreter\n",
    "from treeinterpreter import treeinterpreter as ti\n",
    "\n",
    "rf = RandomForestRegressor(max_features=8, n_estimators=200)\n",
    "rf.fit(X_train,y_train)\n",
    "\n",
    "prediction, bias, contributions = ti.predict(rf, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0aea707",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, bias, contributions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
